{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ultra_omega_alpha_kmeans\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import sys\n",
    "#from dadosdor import recupera_dados \n",
    "\n",
    "\n",
    "distancia_euclidiana = lambda x,y: np.sqrt(((x-y)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaMediaIntra2(conj_dados): #silhueta para dados \n",
    "       \n",
    "    resultado = [] #guarda distancia médio de cada dado para os outros dados do conjunto de dados\n",
    "\n",
    "    for dado in conj_dados:\n",
    "        dist_soma = 0\n",
    "        for dado_2 in conj_dados:\n",
    "            dist_soma = dist_soma + distancia_euclidiana(dado,dado_2)\n",
    "        resultado.append(dist_soma/(len(conj_dados)-1)) ##ANALISAR A FORMULA\n",
    "\n",
    "    return resultado\n",
    "\n",
    "def distanciaMediaExtra2(numero_do_meu_cluster,conj_cluster_dados): #silhueta para dados extracluster\n",
    "\n",
    "    conj_dados = conj_cluster_dados[numero_do_meu_cluster] #pegando os dados para o cluster numero_do_meu_cluster\n",
    "\n",
    "    resultado = []\n",
    "\n",
    "    for dado in conj_dados:\n",
    "\n",
    "        dist_soma = 0\n",
    "        soma_media_min = sys.maxsize\n",
    "        \n",
    "        i = 0\n",
    "        for cluster_externo in conj_cluster_dados:\n",
    "\n",
    "            if i == numero_do_meu_cluster: # é o cluster do dado que estamos calculando a distancia\n",
    "                i = i + 1\n",
    "                continue\n",
    "\n",
    "            soma_temp = 0\n",
    "\n",
    "            for dado_externo in cluster_externo: \n",
    "                soma_temp = soma_temp + distancia_euclidiana(dado,dado_externo)\n",
    "\n",
    "            soma_temp = soma_temp/len(dado_externo) #calculando a distancia média \n",
    "\n",
    "            if soma_temp < soma_media_min :\n",
    "                soma_media_min = soma_temp\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        resultado.append(soma_media_min)\n",
    "    \n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularSilhueta(kmeans):\n",
    "\n",
    "    silhueta_dados = []\n",
    "\n",
    "    my_cluster =  kmeans.clusters #coordenadas para os dados \n",
    "    my_dados = kmeans.dados # matriz de dados - Para acessar um dado devemos consultar a cordenada em my_cluters (lista de listas)\n",
    "\n",
    "    conj_daora = criarConjunto(my_cluster, my_dados)\n",
    "    \n",
    "    #Limpando memória\n",
    "    my_cluster = None\n",
    "    my_dados = None\n",
    "\n",
    "    silhueta_dados = SilhuetaDado(conj_daora) \n",
    "    \n",
    "    silhueta_grupos = [SilhuetaGrupo(grupo) for grupo in silhueta_dados]\n",
    "\n",
    "    silhueta_grupos = np.array(silhueta_grupos)\n",
    "\n",
    "    result = SilhuetaTotal(silhueta_grupos)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularSilhueta(kmeans):\n",
    "\n",
    "    silhueta_dados = []\n",
    "\n",
    "    my_cluster =  kmeans.clusters #coordenadas para os dados \n",
    "    my_dados = kmeans.dados # matriz de dados - Para acessar um dado devemos consultar a cordenada em my_cluters (lista de listas)\n",
    "\n",
    "    conj_daora = criarConjunto(my_cluster, my_dados)\n",
    "    \n",
    "    #Limpando memória\n",
    "    my_cluster = None\n",
    "    my_dados = None\n",
    "\n",
    "    silhueta_dados = SilhuetaDado(conj_daora) \n",
    "    \n",
    "    silhueta_grupos = [SilhuetaGrupo(grupo) for grupo in silhueta_dados]\n",
    "\n",
    "    silhueta_grupos = np.array(silhueta_grupos)\n",
    "\n",
    "    result = SilhuetaTotal(silhueta_grupos)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarConjunto(clusters, dados):\n",
    "    conj_daora = [[] for _ in range(len(clusters))]\n",
    "    i = 0\n",
    "    for my_cluster in clusters: #my_clus\n",
    "        #conj_daora.append([])\n",
    "\n",
    "        for coordenadas in my_cluster:\n",
    "\n",
    "            mydado = dados[coordenadas]\n",
    "            conj_daora[i].append(mydado)\n",
    "\n",
    "        i = i+1\n",
    "    return conj_daora\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devolve uma lista de organizada pelo numero do cluster\n",
    "def distanciaMediaExtra(conj_cluster_dados): #silhueta para dados extracluster    \n",
    "\n",
    "    resultado = []\n",
    "    \n",
    "    hash_dist = {} \n",
    "    #STRUCT ---> key (cluster1_indiceDado1_cluster2_indiceDado2): value = distancia(dado1,dado2) <---\n",
    "    \n",
    "\n",
    "    for cN,cluster in enumerate(conj_cluster_dados):\n",
    "        \n",
    "        resultado_cluster = [] #resultado parcial das distancias extras para o cluster cN\n",
    "\n",
    "        for dN,dado in enumerate(cluster): \n",
    "\n",
    "            soma_media_min = np.inf\n",
    "\n",
    "            for cK,cluster2 in enumerate(conj_cluster_dados): #escolhendo outro cluster\n",
    "\n",
    "                if(cN == cK): #garante que é um cluster diferente\n",
    "                    continue\n",
    "\n",
    "                soma_media_cluster2 = 0\n",
    "\n",
    "                for dK, dado2 in enumerate(cluster2): \n",
    "                    #ordenando a key do dict\n",
    "                    myKey = str(sorted([(cN,dN),(cK,dK)])) #Muito TOP #cria um\n",
    "                    aux = 0 \n",
    "\n",
    "                    if(myKey in hash_dist.keys()): #distancia conhecida? Sim, então não calcula distancia\n",
    "                        aux = hash_dist[myKey]\n",
    "                    else:\n",
    "                        myDist = distancia_euclidiana(dado,dado2) # distancia conhecida? Não , então calcula dist\n",
    "                        hash_dist[myKey] = myDist\n",
    "                        aux = myDist\n",
    "\n",
    "                    soma_media_cluster2 = soma_media_cluster2 + aux # soma dist dos dados\n",
    "\n",
    "                soma_media_cluster2 = soma_media_cluster2/ len(cluster2) #calc media das distancia\n",
    "\n",
    "                if(soma_media_cluster2 < soma_media_min): # é a menor média? \n",
    "                    soma_media_min = soma_media_cluster2 \n",
    "            \n",
    "            resultado_cluster.append(soma_media_min) #salvando o valor da menor média do dado em resultado_cluster\n",
    "\n",
    "        resultado.append(resultado_cluster) #salva a média mínima  para todos os cluster e seus respectivos dados no resultado\n",
    "\n",
    "    return resultado #retorno\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaMediaIntra(conj_dados): #silhueta para dados \n",
    "       \n",
    "    resultado = [] #guarda distancia médio de cada dado para os outros dados do conjunto de dados\n",
    "    matriz_distancias = np.full((len(conj_dados),len(conj_dados)), np.nan)\n",
    "    \n",
    "    for i,dado in enumerate(conj_dados):\n",
    "        dist_soma = 0\n",
    "\n",
    "        for j,dado_2 in enumerate(conj_dados):\n",
    "            aux = 0\n",
    "            if(np.isnan(matriz_distancias[i][j])):\n",
    "                aux =  distancia_euclidiana(dado,dado_2)\n",
    "                matriz_distancias[i][j] = aux\n",
    "                matriz_distancias[j][i] = aux\n",
    "\n",
    "            else:\n",
    "                aux = matriz_distancias[i][j]\n",
    "\n",
    "            dist_soma = dist_soma + aux\n",
    "\n",
    "        resultado.append(dist_soma/(len(conj_dados)-1)) ##ANALISAR A FORMULA\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SilhuetaDado(conj_cluster_dados):\n",
    "\n",
    "    list_conj_a = [distanciaMediaIntra(conj_cluster_dados[x]) for x in range(len(conj_cluster_dados))] # passando o conjunto de dados referente ao cluster em avaliação\n",
    "    \n",
    "    list_conj_b = distanciaMediaExtra(conj_cluster_dados)\n",
    "    \n",
    "\n",
    "    resultado = []\n",
    "\n",
    "    for a,b in zip(list_conj_a,list_conj_b):\n",
    "        a = np.array(a) # lista de distancias intra\n",
    "        b = np.array(b) # lista de distancias extra\n",
    "\n",
    "        c = np.concatenate([[a],[b]], axis = 0).max(axis = 0) #este é o denominador da silhueta- é o maximo entre a e b para todos os valores do vetor\n",
    "        \n",
    "        silhueta = (b-a)/c #Daora\n",
    "        \n",
    "        resultado.append(silhueta)\n",
    "    return np.array(resultado) #valor de silhueta para cada dado do cluster para todos os cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def SilhuetaGrupo(conj_silhueta_dados):\n",
    "    return conj_silhueta_dados.sum()/len(conj_silhueta_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SilhuetaTotal(conj_silhueta_grupo):\n",
    "    conj = np.array(conj_silhueta_grupo)\n",
    "    return conj.sum()/len(conj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = pickle.load(open(\"Word2VecLSA.aug\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.15410197e-01, -2.81331897e-01,  1.59294859e-01, ...,\n",
       "        -1.80752855e-02,  1.56170996e-02, -6.23486973e-02],\n",
       "       [ 8.70225549e-01, -2.31178373e-01, -8.74117240e-02, ...,\n",
       "         4.75417152e-02, -1.42433485e-02,  2.06052009e-02],\n",
       "       [ 7.37318873e-01, -2.63734460e-01, -1.30225077e-01, ...,\n",
       "        -3.87579203e-02, -5.48125128e-04, -9.49290581e-03],\n",
       "       ...,\n",
       "       [ 9.12091732e-01, -1.88202366e-01,  2.33981516e-02, ...,\n",
       "         2.04208810e-02,  1.28419381e-02,  9.50750615e-03],\n",
       "       [ 8.30604553e-01, -2.17120945e-01,  9.28634126e-03, ...,\n",
       "         5.45509011e-02, -5.94339753e-03,  2.10989788e-02],\n",
       "       [ 8.81490827e-01,  1.13582820e-01,  1.02059469e-01, ...,\n",
       "        -1.27179045e-02,  3.47219827e-03,  2.42763525e-03]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmenzao = ultra_omega_alpha_kmeans.ultra_omega_alpha_kmeans(no_clusters, inicializacao = \"++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% (7 of 500) |                        | Elapsed Time: 0:00:00 ETA:   0:00:43"
     ]
    }
   ],
   "source": [
    "kmenzao.incluir(arquivo)\n",
    "kmenzao.inicializar()\n",
    "kmenzao.executar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conj = criarConjunto(kmenzao.clusters, kmenzao.dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%time intra = distanciaMediaIntra(conj[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%time intra = distanciaMediaIntra2(conj[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%time extra= distanciaMediaExtra(conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%time extra= [distanciaMediaExtra2(x,conj) for x in range(2)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
