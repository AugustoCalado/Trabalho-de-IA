{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ultra_omega_alpha_kmeans_multicore\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "#from dadosdor import recupera_dados \n",
    "\n",
    "\n",
    "distancia_euclidiana = lambda x,y: np.sqrt(((x-y)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaMediaIntra2(conj_dados): #silhueta para dados \n",
    "       \n",
    "    resultado = [] #guarda distancia médio de cada dado para os outros dados do conjunto de dados\n",
    "\n",
    "    for dado in conj_dados:\n",
    "        dist_soma = 0\n",
    "        for dado_2 in conj_dados:\n",
    "            dist_soma = dist_soma + distancia_euclidiana(dado,dado_2)\n",
    "        resultado.append(dist_soma/(len(conj_dados)-1)) ##ANALISAR A FORMULA\n",
    "\n",
    "    return resultado\n",
    "\n",
    "def distanciaMediaExtra2(numero_do_meu_cluster,conj_cluster_dados): #silhueta para dados extracluster\n",
    "\n",
    "    conj_dados = conj_cluster_dados[numero_do_meu_cluster] #pegando os dados para o cluster numero_do_meu_cluster\n",
    "\n",
    "    resultado = []\n",
    "\n",
    "    for dado in conj_dados:\n",
    "\n",
    "        dist_soma = 0\n",
    "        soma_media_min = sys.maxsize\n",
    "        \n",
    "        i = 0\n",
    "        for cluster_externo in conj_cluster_dados:\n",
    "\n",
    "            if i == numero_do_meu_cluster: # é o cluster do dado que estamos calculando a distancia\n",
    "                i = i + 1\n",
    "                continue\n",
    "\n",
    "            soma_temp = 0\n",
    "\n",
    "            for dado_externo in cluster_externo: \n",
    "                soma_temp = soma_temp + distancia_euclidiana(dado,dado_externo)\n",
    "\n",
    "            soma_temp = soma_temp/len(dado_externo) #calculando a distancia média \n",
    "\n",
    "            if soma_temp < soma_media_min :\n",
    "                soma_media_min = soma_temp\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        resultado.append(soma_media_min)\n",
    "    \n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularSilhueta(kmeans):\n",
    "\n",
    "    silhueta_dados = []\n",
    "\n",
    "    my_cluster =  kmeans.clusters #coordenadas para os dados \n",
    "    my_dados = kmeans.dados # matriz de dados - Para acessar um dado devemos consultar a cordenada em my_cluters (lista de listas)\n",
    "\n",
    "    conj_daora = criarConjunto(my_cluster, my_dados)\n",
    "    \n",
    "    #Limpando memória\n",
    "    my_cluster = None\n",
    "    my_dados = None\n",
    "\n",
    "    silhueta_dados = SilhuetaDado(conj_daora) \n",
    "    \n",
    "    silhueta_grupos = [SilhuetaGrupo(grupo) for grupo in silhueta_dados]\n",
    "\n",
    "    silhueta_grupos = np.array(silhueta_grupos)\n",
    "\n",
    "    result = SilhuetaTotal(silhueta_grupos)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularSilhueta(kmeans):\n",
    "\n",
    "    silhueta_dados = []\n",
    "\n",
    "    my_cluster =  kmeans.clusters #coordenadas para os dados \n",
    "    my_dados = kmeans.dados # matriz de dados - Para acessar um dado devemos consultar a cordenada em my_cluters (lista de listas)\n",
    "\n",
    "    conj_daora = criarConjunto(my_cluster, my_dados)\n",
    "    \n",
    "    #Limpando memória\n",
    "    my_cluster = None\n",
    "    my_dados = None\n",
    "\n",
    "    silhueta_dados = SilhuetaDado(conj_daora) \n",
    "    \n",
    "    silhueta_grupos = [SilhuetaGrupo(grupo) for grupo in silhueta_dados]\n",
    "\n",
    "    silhueta_grupos = np.array(silhueta_grupos)\n",
    "\n",
    "    result = SilhuetaTotal(silhueta_grupos)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarConjunto(clusters, dados):\n",
    "    conj_daora = [[] for _ in range(len(clusters))]\n",
    "    i = 0\n",
    "    for my_cluster in clusters: #my_clus\n",
    "        #conj_daora.append([])\n",
    "\n",
    "        for coordenadas in my_cluster:\n",
    "\n",
    "            mydado = dados[coordenadas]\n",
    "            conj_daora[i].append(mydado)\n",
    "\n",
    "        i = i+1\n",
    "    return conj_daora\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaMediaExtra4x4(conj_cluster_dados):\n",
    "    \n",
    "    maxZ = np.max([len(x) for x in conj_cluster_dados]) #selected a maior lista que existe para um cluster\n",
    "       \n",
    "    \n",
    "    matriz_distancias = np.full((len(conj_cluster_dados),maxZ,len(conj_cluster_dados),maxZ), np.nan)\n",
    "    \n",
    "    resultado = []\n",
    "    \n",
    "     \n",
    "    #STRUCT ---> key (cluster1_indiceDado1_cluster2_indiceDado2): value = distancia(dado1,dado2) <---\n",
    "    \n",
    "\n",
    "    for cN,cluster in enumerate(conj_cluster_dados):\n",
    "        \n",
    "        resultado_cluster = [] #resultado parcial das distancias extras para o cluster cN\n",
    "\n",
    "        for dN,dado in enumerate(cluster): \n",
    "\n",
    "            soma_media_min = np.inf\n",
    "\n",
    "            for cK,cluster2 in enumerate(conj_cluster_dados): #escolhendo outro cluster\n",
    "\n",
    "                if(cN == cK): #garante que é um cluster diferente\n",
    "                    continue\n",
    "\n",
    "                soma_media_cluster2 = 0\n",
    "\n",
    "                for dK, dado2 in enumerate(cluster2): \n",
    "                    #ordenando a key do dict\n",
    "                    myValue = matriz_distancias[cN][dN][cK][dK]\n",
    "                    aux = 0 \n",
    "\n",
    "                    if not np.isnan(myValue): #distancia conhecida? Sim, então não calcula distancia\n",
    "                        aux =  myValue\n",
    "                    else:\n",
    "                        myDist = distancia_euclidiana(dado,dado2) # distancia conhecida? Não , então calcula dist\n",
    "                        matriz_distancias[cN][dN][cK][dK] = myDist\n",
    "                        matriz_distancias[cK][dK][cN][dN] = myDist\n",
    "                        aux = myDist\n",
    "                        \n",
    "\n",
    "                    soma_media_cluster2 = soma_media_cluster2 + aux # soma dist dos dados\n",
    "\n",
    "                soma_media_cluster2 = soma_media_cluster2/ len(cluster2) #calc media das distancia\n",
    "\n",
    "                if(soma_media_cluster2 < soma_media_min): # é a menor média? \n",
    "                    soma_media_min = soma_media_cluster2 \n",
    "            \n",
    "            resultado_cluster.append(soma_media_min) #salvando o valor da menor média do dado em resultado_cluster\n",
    "\n",
    "        resultado.append(resultado_cluster) #salva a média mínima  para todos os cluster e seus respectivos dados no resultado\n",
    "\n",
    "    return resultado #retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devolve uma lista de organizada pelo numero do cluster\n",
    "def distanciaMediaExtra(conj_cluster_dados): #silhueta para dados extracluster    \n",
    "\n",
    "    resultado = []\n",
    "    \n",
    "    hash_dist = {} \n",
    "    #STRUCT ---> key (cluster1_indiceDado1_cluster2_indiceDado2): value = distancia(dado1,dado2) <---\n",
    "    \n",
    "\n",
    "    for cN,cluster in enumerate(conj_cluster_dados):\n",
    "        \n",
    "        resultado_cluster = [] #resultado parcial das distancias extras para o cluster cN\n",
    "\n",
    "        for dN,dado in enumerate(cluster): \n",
    "\n",
    "            soma_media_min = np.inf\n",
    "\n",
    "            for cK,cluster2 in enumerate(conj_cluster_dados): #escolhendo outro cluster\n",
    "\n",
    "                if(cN == cK): #garante que é um cluster diferente\n",
    "                    continue\n",
    "\n",
    "                soma_media_cluster2 = 0\n",
    "\n",
    "                for dK, dado2 in enumerate(cluster2): \n",
    "                    #ordenando a key do dict\n",
    "                    myKey = str(sorted([(cN,dN),(cK,dK)])) #Muito TOP #cria um\n",
    "                    aux = 0 \n",
    "\n",
    "                    if(myKey in hash_dist.keys()): #distancia conhecida? Sim, então não calcula distancia\n",
    "                        aux = hash_dist[myKey]\n",
    "                    else:\n",
    "                        myDist = distancia_euclidiana(dado,dado2) # distancia conhecida? Não , então calcula dist\n",
    "                        hash_dist[myKey] = myDist\n",
    "                        aux = myDist\n",
    "\n",
    "                    soma_media_cluster2 = soma_media_cluster2 + aux # soma dist dos dados\n",
    "\n",
    "                soma_media_cluster2 = soma_media_cluster2/ len(cluster2) #calc media das distancia\n",
    "\n",
    "                if(soma_media_cluster2 < soma_media_min): # é a menor média? \n",
    "                    soma_media_min = soma_media_cluster2 \n",
    "            \n",
    "            resultado_cluster.append(soma_media_min) #salvando o valor da menor média do dado em resultado_cluster\n",
    "\n",
    "        resultado.append(resultado_cluster) #salva a média mínima  para todos os cluster e seus respectivos dados no resultado\n",
    "\n",
    "    return resultado #retorno\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanciaMediaIntra(conj_dados): #silhueta para dados \n",
    "       \n",
    "    resultado = [] #guarda distancia médio de cada dado para os outros dados do conjunto de dados\n",
    "    matriz_distancias = np.full((len(conj_dados),len(conj_dados)), np.nan)\n",
    "    \n",
    "    for i,dado in enumerate(conj_dados):\n",
    "        dist_soma = 0\n",
    "\n",
    "        for j,dado_2 in enumerate(conj_dados):\n",
    "            aux = 0\n",
    "            if(np.isnan(matriz_distancias[i][j])):\n",
    "                aux =  distancia_euclidiana(dado,dado_2)\n",
    "                matriz_distancias[i][j] = aux\n",
    "                matriz_distancias[j][i] = aux\n",
    "\n",
    "            else:\n",
    "                aux = matriz_distancias[i][j]\n",
    "\n",
    "            dist_soma = dist_soma + aux\n",
    "\n",
    "        resultado.append(dist_soma/(len(conj_dados)-1)) ##ANALISAR A FORMULA\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SilhuetaDado(conj_cluster_dados):\n",
    "\n",
    "    #list_conj_a = [distanciaMediaIntra(conj_cluster_dados[x]) for x in range(len(conj_cluster_dados))] # passando o conjunto de dados referente ao cluster em avaliação\n",
    "    \n",
    "    list_conj_a = Parallel(n_jobs=-1,  backend=\"threading\") (distanciaMediaIntra(conj_cluster_dados[x]) for x in range(len(conj_cluster_dados))) # passando o conjunto de dados referente ao cluster em avaliação\n",
    "    \n",
    "    \n",
    "    list_conj_b = distanciaMediaExtra4x4(conj_cluster_dados)\n",
    "    \n",
    "\n",
    "    resultado = []\n",
    "\n",
    "    for a,b in zip(list_conj_a,list_conj_b):\n",
    "        a = np.array(a) # lista de distancias intra\n",
    "        b = np.array(b) # lista de distancias extra\n",
    "\n",
    "        c = np.concatenate([[a],[b]], axis = 0).max(axis = 0) #este é o denominador da silhueta- é o maximo entre a e b para todos os valores do vetor\n",
    "        \n",
    "        silhueta = (b-a)/c #Daora\n",
    "        \n",
    "        resultado.append(silhueta)\n",
    "    return np.array(resultado) #valor de silhueta para cada dado do cluster para todos os cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def SilhuetaGrupo(conj_silhueta_dados):\n",
    "    return conj_silhueta_dados.sum()/len(conj_silhueta_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SilhuetaTotal(conj_silhueta_grupo):\n",
    "    conj = np.array(conj_silhueta_grupo)\n",
    "    return conj.sum()/len(conj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = pickle.load(open(\"arq.aug\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo\n",
    "arquivo = np.array(arquivo.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmenzao = ultra_omega_alpha_kmeans_multicore.ultra_omega_alpha_kmeans(no_clusters = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (25 of 500) |#                      | Elapsed Time: 0:02:58 ETA:   0:56:29"
     ]
    }
   ],
   "source": [
    "kmenzao.incluir(arquivo)\n",
    "kmenzao.inicializar()\n",
    "kmenzao.executar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conj = criarConjunto(kmenzao.clusters, kmenzao.dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time calcularSilhueta(kmenzao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time intra =  [distanciaMediaIntra(conj[x]) for x in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time intra =  [distanciaMediaIntra2(conj[x]) for x in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time extra= distanciaMediaExtra(conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time extra= distanciaMediaExtra4x4(conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time extra= [distanciaMediaExtra2(x,conj) for x in range(10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
