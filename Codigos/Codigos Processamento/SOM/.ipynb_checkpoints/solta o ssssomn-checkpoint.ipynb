{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import somoclu\n",
    "import sys, os\n",
    "import pathlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "from sklearn.cluster import KMeans\n",
    "import silhuetaDInamico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Kmeanz:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusterizacao(som):\n",
    "    resposta=[[] for _ in range(som.clusters.max()+1)]\n",
    "    for pos,valor in enumerate(som.bmus):\n",
    "        my_cluster= som.clusters[valor[0]][valor[1]]\n",
    "        resposta[my_cluster].append(pos)\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path_arquivos = \"../../../Objetos/ObjetosPreProcessados Amostra/\"\n",
    "    # Retorna tudo oque tem dentro de ObjetosPreProcessados -> só há pastas\n",
    "    tipos_de_representacao = os.listdir(path_arquivos)\n",
    "    escolha_da_representacao = sys.argv[1]  # entrada via prompt (string)\n",
    "    \n",
    "\n",
    "    if escolha_da_representacao not in tipos_de_representacao:\n",
    "        raise ValueError(\"Voce nao digitou uma entrada valida\")\n",
    "\n",
    "    #tipos_de_tamanho = os.listdir(path_arquivos + escolha_da_representacao)\n",
    "    tipos_de_tamanho = [\"3k\"]\n",
    "\n",
    "    algoritmos_do_kmenzao = [\"media\"]\n",
    "    distancias_do_kmenzao = [\"euclidiana\", \"manhattan\", \"cosseno\"]\n",
    "\n",
    "    resposta = []\n",
    "\n",
    "\n",
    "    for tipo_de_tamanho in tipos_de_tamanho:\n",
    "        #tipos_de_tipo = os.listdir(path_arquivos + escolha_da_representacao + \"/\" + tipo_de_tamanho)\n",
    "        tipos_de_tipo = [\"Normal\",\"Lemma\"]\n",
    "        for tipo_de_tipo in tipos_de_tipo: #Normal ou Lema\n",
    "            objetos = os.listdir(path_arquivos + escolha_da_representacao + \"/\" + tipo_de_tamanho + \"/\" + tipo_de_tipo)\n",
    "\n",
    "            for objeto in objetos:\n",
    "                with open(\n",
    "                        path_arquivos + escolha_da_representacao + \"/\" + tipo_de_tamanho + \"/\" + tipo_de_tipo + \"/\" + objeto,\n",
    "                        \"rb\") as f1:\n",
    "                    come_xuchu = pickle.load(f1) #Abre Representa;áo\n",
    "\n",
    "                if (not isinstance(come_xuchu, np.ndarray)):\n",
    "                    come_xuchu = np.array(come_xuchu.todense(), dtype=np.float64)\n",
    "                lsa = False\n",
    "\n",
    "                # print(\"TSNING...\")\n",
    "                # tsne = TSNE(n_components=3)\n",
    "                # transform_come_xuchu = tsne.fit_transform(come_xuchu)\n",
    "                # pickle.dump(transform_come_xuchu,open(\"../../../Objetos/ObjetosProcessados/\"+escolha_da_representacao +\"/\"+tipo_de_tamanho +\"/\"+ tipo_de_tipo + \"/\"+ \"bbc_\" + escolha_da_representacao + \"_\" + tipo_de_tamanho + \"_\" + tipo_de_tipo + \"_LSA\" + str(lsa) +\".tsne\",\"wb\"))\n",
    "\n",
    "                if (\"LSA\" in objeto):\n",
    "                    lsa = True\n",
    "\n",
    "                print(\"Somando...\", escolha_da_representacao, tipo_de_tamanho, tipo_de_tipo, lsa, \":D\") \n",
    "                for grid_size in [7,10,14]:\n",
    "                    for learning_rate in [0.1,0.4,0.7]:\n",
    "                        for neighboorhood_radius  in [int(grid_size/2),2,1]:\n",
    "                            for r_cooling in ['linear','exponential']:\n",
    "                                for a_cooling in ['linear','exponential']:\n",
    "                                    \n",
    "                                    som = somoclu.Somoclu(grid_size, grid_size,verbose =2)\n",
    "                                    som.train(data=come_xuchu,epochs=1000,radius0=neighboorhood_radius,radiusN=1,radiuscooling=r_cooling,scale0=learning_rate,scaleN=0.01,scalecooling=a_cooling)\n",
    "                                    for n in range(2,8):\n",
    "                                        silhueta_acumulador=0\n",
    "                                        for _ in range(30):\n",
    "                                            flaag=True\n",
    "                                            while(flaag):\n",
    "                                                try:\n",
    "                                                    kmeans=KMeans(n_clusters=n)\n",
    "                                                    som.cluster(kmeans)\n",
    "                                                    kmeanz = Kmeanz()\n",
    "                                                    kmeanz.clusters= clusterizacao(som)\n",
    "                                                    kmeanz.dados= come_xuchu\n",
    "                                                    silhueta_final = silhuetaDInamico.calcularSilhueta(kmeans)\n",
    "                                                    silhueta_acumulador = silhueta_acumulador + silhueta_final\n",
    "                                                    flaag=False\n",
    "                                                except:\n",
    "                                                    print(\"error founddd\")\n",
    "                                        \n",
    "                                        silhueta_acumulador = silhueta_acumulador/30\n",
    "                                        \n",
    "                                        come_xuchu_dict = {}\n",
    "                                        come_xuchu_dict[\"corpus\"] = \"bbc\"\n",
    "                                        come_xuchu_dict[\"representacao\"] = escolha_da_representacao\n",
    "                                        come_xuchu_dict[\"tamanho\"] = tipo_de_tamanho\n",
    "                                        come_xuchu_dict[\"processamento\"] = tipo_de_tipo\n",
    "                                        come_xuchu_dict[\"LSA\"] = lsa\n",
    "                                        come_xuchu_dict[\"ncluster\"] = n\n",
    "                                        come_xuchu_dict[\"grid_size\"] = grid_size\n",
    "                                        come_xuchu_dict[\"learning_rate\"] = learning_rate\n",
    "                                        come_xuchu_dict[\"neighboorhood_radius\"] = neighboorhood_radius\n",
    "                                        come_xuchu_dict[\"r_cooling\"] = r_cooling\n",
    "                                        come_xuchu_dict[\"a_cooling\"] = a_cooling\n",
    "                                        \n",
    "                                        resposta.append((silhueta_acumulador, come_xuchu_dict))\n",
    "    \n",
    "    pickle.dump(resposta,open(\"som\"+escolha_da_representacao + str(numero_de_cluster) + \".jojo\", \"wb\"))\n",
    "                                        \n",
    "                        \n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
